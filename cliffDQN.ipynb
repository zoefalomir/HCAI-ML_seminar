{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/gDhvcuP.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://i.imgur.com/gDhvcuP.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 6\n",
    "COLS = 10\n",
    "S = [ROWS-1, 0]\n",
    "G = [ROWS-1, COLS-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cliff:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize a cliff instance\n",
    "        \"\"\"\n",
    "        self.done = False\n",
    "        self.pos = S\n",
    "        self.board = np.zeros([ROWS, COLS])\n",
    "        # set the location of the cliff\n",
    "        self.board[ROWS-1, 1:-1] = -1\n",
    "        \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Given an action, return the agent's next position\n",
    "        \"\"\"\n",
    "        assert action in [0, 1, 2, 3]\n",
    "        # up\n",
    "        if action == 0:\n",
    "            next_pos = [self.pos[0]-1, self.pos[1]]\n",
    "        # down\n",
    "        elif action == 1:\n",
    "            next_pos = [self.pos[0]+1, self.pos[1]]\n",
    "        # left\n",
    "        elif action == 2:\n",
    "            next_pos = [self.pos[0], self.pos[1]-1]\n",
    "        # right\n",
    "        else:\n",
    "            next_pos = [self.pos[0], self.pos[1]+1]\n",
    "\n",
    "        # make sure that the agent does not go out of bounds\n",
    "        if next_pos[0] >= 0 and next_pos[0] < ROWS:\n",
    "            if next_pos[1] >= 0 and next_pos[1] < COLS:\n",
    "                self.pos = next_pos\n",
    "        \n",
    "        # reward per step\n",
    "        reward = -5.0\n",
    "        self.done = False\n",
    "        \n",
    "        if self.pos == G:\n",
    "            self.done = True\n",
    "            reward = 100\n",
    "            print(\"Reached goal\")\n",
    "        \n",
    "        if self.board[self.pos[0], self.pos[1]] == -1:\n",
    "            self.done = True\n",
    "            reward = -100.0\n",
    "            print(\"Fell off cliff\")\n",
    "            \n",
    "        return self.pos, reward, self.done\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the agent's position to the starting position\n",
    "        \"\"\"\n",
    "        self.pos = S\n",
    "        return self.pos\n",
    "    \n",
    "    def show(self):\n",
    "        \"\"\"\n",
    "        Displays the cliff environment\n",
    "        \"\"\"\n",
    "        for i in range(ROWS):\n",
    "            print('----' * COLS + '-')\n",
    "            out = '| '\n",
    "            for j in range(COLS):\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = 'o'\n",
    "                if [i, j] == self.pos:\n",
    "                    token = 'S'\n",
    "                if [i, j] == G:\n",
    "                    token = 'G'\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('----' * COLS + '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        \"\"\"\n",
    "        Initialize the DQN Agent\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.9   \n",
    "        self.epsilon = 1.0 \n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99995 \n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        \"\"\"\n",
    "        Builds a simple Q-Network composed of linear layers\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "        Given a state, returns the action the agent takes\n",
    "        \"\"\"\n",
    "        # randomly select action\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        # use Q-Network to predict action\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  \n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        \"\"\"\n",
    "        Trains the Q-Network using experiences in the agent's memory\n",
    "        \"\"\"\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        states, targets_f = [], []\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            # if done, set target = reward\n",
    "            target = reward\n",
    "            # if not done, predict future discounted reward with the Bellman equation\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target \n",
    "            # filtering out states and targets for training\n",
    "            states.append(state[0])\n",
    "            targets_f.append(target_f[0])\n",
    "        history = self.model.fit(np.array(states), np.array(targets_f), epochs=1, verbose=0)\n",
    "        # keeping track of loss\n",
    "        loss = history.history['loss'][0]\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        return loss\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| o | o | o | o | o | o | o | o | o | o | \n",
      "-----------------------------------------\n",
      "| o | o | o | o | o | o | o | o | o | o | \n",
      "-----------------------------------------\n",
      "| o | o | o | o | o | o | o | o | o | o | \n",
      "-----------------------------------------\n",
      "| o | o | o | o | o | o | o | o | o | o | \n",
      "-----------------------------------------\n",
      "| o | o | o | o | o | o | o | o | o | o | \n",
      "-----------------------------------------\n",
      "| S | x | x | x | x | x | x | x | x | G | \n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = Cliff()\n",
    "state_size = 2 # state = (x, y) coordinate of agent's location\n",
    "action_size = 4 # action: go up, down, left, or right\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "# agent.load(\"./agent_weights.h5\")\n",
    "batch_size = 64\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fell off cliff\n",
      "episode: 0/5, timestep: 0, epsilon: 1.0\n",
      "HEATMAP FOR EPISODE 0\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~\n",
      "Time for episode 0 = 0m 0s\n",
      "~~~~~~~~~\n",
      "Fell off cliff\n",
      "episode: 1/5, timestep: 2, epsilon: 1.0\n",
      "HEATMAP FOR EPISODE 1\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [2 2 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~\n",
      "Time for episode 1 = 0m 0s\n",
      "~~~~~~~~~\n",
      "Time for episode 2 = 0m 0s\n",
      "~~~~~~~~~\n",
      "Fell off cliff\n",
      "episode: 3/5, timestep: 6, epsilon: 1.0\n",
      "HEATMAP FOR EPISODE 3\n",
      "[[0 0 1 2 5 6 1 0 0 0]\n",
      " [1 0 2 1 3 2 0 0 0 0]\n",
      " [3 1 3 0 2 2 0 0 0 0]\n",
      " [6 3 2 0 1 2 0 0 0 0]\n",
      " [4 1 1 0 0 0 0 0 0 0]\n",
      " [3 3 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~\n",
      "Time for episode 3 = 0m 0s\n",
      "~~~~~~~~~\n",
      "Fell off cliff\n",
      "episode: 4/5, timestep: 1, epsilon: 1.0\n",
      "HEATMAP FOR EPISODE 4\n",
      "[[0 0 1 2 5 6 1 0 0 0]\n",
      " [1 0 2 1 3 2 0 0 0 0]\n",
      " [3 1 3 0 2 2 0 0 0 0]\n",
      " [6 3 2 0 1 2 0 0 0 0]\n",
      " [4 1 1 0 0 0 0 0 0 0]\n",
      " [4 4 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~\n",
      "Time for episode 4 = 0m 0s\n",
      "~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "\n",
    "EPISODES = 5 # change to 5000 if actually training\n",
    "heatmap = np.zeros([ROWS, COLS])\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    since = time.time()\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for t in range(50): # change to 500 if actually training\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.memorize(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        \n",
    "        # CREATE/SAVE HEATMAP\n",
    "        heatmap[state[0][0]][state[0][1]] += 1\n",
    "        np.savetxt(\"heatmap.txt\", heatmap)\n",
    "        \n",
    "        if done:\n",
    "            print(\"episode: {}/{}, timestep: {}, epsilon: {}\".format(e, EPISODES, t, agent.epsilon)) \n",
    "            print(\"HEATMAP FOR EPISODE {}\".format(e))\n",
    "            print(heatmap.astype(\"int\"))\n",
    "            plt.imshow(heatmap)\n",
    "            plt.show()\n",
    "            print(\"~~~~~~~~~\")\n",
    "            break\n",
    "        \n",
    "        if len(agent.memory) > batch_size:\n",
    "            loss = agent.replay(batch_size)\n",
    "            # logging training loss every 10 timesteps\n",
    "            if t % 10 == 0:\n",
    "                print(\"episode: {}/{}, timestep: {}, epsilon: {}\".format(e, EPISODES, t, agent.epsilon)) \n",
    "                print(\"HEATMAP FOR EPISODE {}\".format(e))\n",
    "                print(heatmap.astype(\"int\"))\n",
    "                plt.imshow(heatmap)\n",
    "                plt.show()\n",
    "                print(\"~~~~~~~~~\")\n",
    "    \n",
    "    # agent.save(\"./agent_weights.h5\")\n",
    "    # print(\"saved weights at episode {}\".format(e))\n",
    "    print('Time for episode {} = {:.0f}m {:.0f}s'.format(e, (time.time() - since) // 60, (time.time() - since) % 60))\n",
    "    print(\"~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained agent\n",
    "\n",
    "# set epsilon to 0 to make the policy deterministic\n",
    "# agent.epsilon = 0.0\n",
    "\n",
    "# def show_route(states):\n",
    "#     \"\"\"\n",
    "#     Shows the route the agent took from the start to the goal\n",
    "#     \"\"\"\n",
    "#     board = np.zeros([ROWS, COLS])\n",
    "#     # add cliff marked as -1\n",
    "#     board[ROWS-1, 1:-1] = -1\n",
    "#     for i in range(ROWS):\n",
    "#         print('----' * COLS + '-')\n",
    "#         out = '| '\n",
    "#         for j in range(COLS):\n",
    "#             token = ' '\n",
    "#             if board[i, j] == -1:\n",
    "#                 token = 'x'\n",
    "#             if [i, j] in states:\n",
    "#                 token = 'R'\n",
    "#             if [i, j] == G:\n",
    "#                 token = 'G'\n",
    "#             if [i, j] == S:\n",
    "#                 token = 'S'\n",
    "#             out += token + ' | '\n",
    "#         print(out)\n",
    "#     print('----' * COLS + '-') \n",
    "\n",
    "# states = []\n",
    "# state = env.reset()\n",
    "# state = np.reshape(state, [1, state_size])\n",
    "# action_map = {0: \"up\", 1: \"down\", 2: \"left\", 3: \"right\"}\n",
    "\n",
    "# while True:\n",
    "#     action = agent.act(state)\n",
    "#     print(\"state: {} action: {}\".format(state, action_map[action]))\n",
    "#     next_state, reward, done = env.step(action)\n",
    "#     states.append(next_state)\n",
    "#     next_state = np.reshape(next_state, [1, state_size])\n",
    "#     state = next_state\n",
    "#     if done:\n",
    "#         break\n",
    "        \n",
    "# show_route(states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
